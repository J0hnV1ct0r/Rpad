{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.animation as animation\n",
    "import numpy as np\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>0.05623</td>\n",
       "      <td>...</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>0.05533</td>\n",
       "      <td>...</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>0.05648</td>\n",
       "      <td>...</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>0.07016</td>\n",
       "      <td>...</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>0.05884</td>\n",
       "      <td>...</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0      1       2       3        4        5        6        7       8  \\\n",
       "0    17.99  10.38  122.80  1001.0  0.11840  0.27760  0.30010  0.14710  0.2419   \n",
       "1    20.57  17.77  132.90  1326.0  0.08474  0.07864  0.08690  0.07017  0.1812   \n",
       "2    19.69  21.25  130.00  1203.0  0.10960  0.15990  0.19740  0.12790  0.2069   \n",
       "3    11.42  20.38   77.58   386.1  0.14250  0.28390  0.24140  0.10520  0.2597   \n",
       "4    20.29  14.34  135.10  1297.0  0.10030  0.13280  0.19800  0.10430  0.1809   \n",
       "..     ...    ...     ...     ...      ...      ...      ...      ...     ...   \n",
       "564  21.56  22.39  142.00  1479.0  0.11100  0.11590  0.24390  0.13890  0.1726   \n",
       "565  20.13  28.25  131.20  1261.0  0.09780  0.10340  0.14400  0.09791  0.1752   \n",
       "566  16.60  28.08  108.30   858.1  0.08455  0.10230  0.09251  0.05302  0.1590   \n",
       "567  20.60  29.33  140.10  1265.0  0.11780  0.27700  0.35140  0.15200  0.2397   \n",
       "568   7.76  24.54   47.92   181.0  0.05263  0.04362  0.00000  0.00000  0.1587   \n",
       "\n",
       "           9  ...     21      22      23       24       25      26      27  \\\n",
       "0    0.07871  ...  17.33  184.60  2019.0  0.16220  0.66560  0.7119  0.2654   \n",
       "1    0.05667  ...  23.41  158.80  1956.0  0.12380  0.18660  0.2416  0.1860   \n",
       "2    0.05999  ...  25.53  152.50  1709.0  0.14440  0.42450  0.4504  0.2430   \n",
       "3    0.09744  ...  26.50   98.87   567.7  0.20980  0.86630  0.6869  0.2575   \n",
       "4    0.05883  ...  16.67  152.20  1575.0  0.13740  0.20500  0.4000  0.1625   \n",
       "..       ...  ...    ...     ...     ...      ...      ...     ...     ...   \n",
       "564  0.05623  ...  26.40  166.10  2027.0  0.14100  0.21130  0.4107  0.2216   \n",
       "565  0.05533  ...  38.25  155.00  1731.0  0.11660  0.19220  0.3215  0.1628   \n",
       "566  0.05648  ...  34.12  126.70  1124.0  0.11390  0.30940  0.3403  0.1418   \n",
       "567  0.07016  ...  39.42  184.60  1821.0  0.16500  0.86810  0.9387  0.2650   \n",
       "568  0.05884  ...  30.37   59.16   268.6  0.08996  0.06444  0.0000  0.0000   \n",
       "\n",
       "         28       29    y  \n",
       "0    0.4601  0.11890  0.0  \n",
       "1    0.2750  0.08902  0.0  \n",
       "2    0.3613  0.08758  0.0  \n",
       "3    0.6638  0.17300  0.0  \n",
       "4    0.2364  0.07678  0.0  \n",
       "..      ...      ...  ...  \n",
       "564  0.2060  0.07115  0.0  \n",
       "565  0.2572  0.06637  0.0  \n",
       "566  0.2218  0.07820  0.0  \n",
       "567  0.4087  0.12400  0.0  \n",
       "568  0.2871  0.07039  1.0  \n",
       "\n",
       "[569 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "breast=pd.read_csv('dados/breast.csv',header=None)\n",
    "breast=breast.rename(columns={breast.columns[30]:'y'})\n",
    "breast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nomalizador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Nomalizer:\n",
    "    def __init__(self):\n",
    "        self.y_max=0.0\n",
    "        self.y_min=0.0\n",
    "        self.x_max=[]\n",
    "        self.x_min=[]\n",
    "\n",
    "    def fit(self,x,y):\n",
    "        # Pega os valores minimos de \n",
    "        self.y_max=y['y'].max().tolist()\n",
    "        self.y_min=y['y'].min().tolist()\n",
    "\n",
    "        # Pega os valores maximos e minimos do X\n",
    "        self.x_max=x.max().tolist()\n",
    "        self.x_min=x.min().tolist()\n",
    "    \n",
    "    def normalize(self,x,y):\n",
    "        y_norm=y.map(self.y_norm_aux)\n",
    "        x_norm=x.copy()\n",
    "        norm_index=0\n",
    "        for column in x.columns:\n",
    "            x_column=[]\n",
    "            for i in range(len(x[column])):\n",
    "                x_column.append((x[column][i]-self.x_min[norm_index])/(self.x_max[norm_index]-self.x_min[norm_index]))\n",
    "                \n",
    "            norm_index+=1\n",
    "            x_norm[column]=x_column    \n",
    "        \n",
    "        return x_norm,y_norm\n",
    "    \n",
    "    def desnormalize(self,x_norm,y_norm):\n",
    "        y=y_norm.map(self.y_desnorm_aux)\n",
    "        x=x_norm.copy()\n",
    "        norm_index=0\n",
    "        for column in x_norm.columns:\n",
    "            x_column=[]\n",
    "            for i in range(len(x_norm[column])):\n",
    "                x_column.append((x_norm[column][i]*(self.x_max[norm_index]-self.x_min[norm_index]))+self.x_min[norm_index])\n",
    "                \n",
    "            norm_index+=1\n",
    "            x[column]=x_column    \n",
    "        \n",
    "        return x,y\n",
    "    \n",
    "    def y_norm_aux(self,y):\n",
    "        return (y-self.y_min)/(self.y_max-self.y_min)\n",
    "    \n",
    "    def y_desnorm_aux(self,y):\n",
    "        return (y*(self.y_max-self.y_min))+self.y_min"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticClassifier:\n",
    "  def __init__(self,opt='SGD'):\n",
    "    self.w =[]\n",
    "    self.losses=[]\n",
    "    \n",
    "\n",
    "  def fit(self, X, y, n, reg, lr=0.001, epochs=100):\n",
    "    x_poli = self.polinomial_transfomation(X,n)# Transforma em polinomio\n",
    "    df_bias = pd.DataFrame({'bias':[1]*len(x_poli)})\n",
    "    X_bias=pd.concat([df_bias,x_poli], axis=1)\n",
    "    self.w=np.ones(X_bias.shape[1])\n",
    "    self.fit_SGD(X_bias,y,reg,lr,epochs)\n",
    "\n",
    "  def polinomial_transfomation(self,x,n):\n",
    "    df_columns = x.columns\n",
    "    poli_columns={}\n",
    "    self.n=n\n",
    "    x_poli=x.copy()\n",
    "    for column in df_columns:\n",
    "      for i in range(2,n+1):\n",
    "        poli_columns[f\"{column}_{i}\"] = x[column]**i\n",
    "    poli_df = pd.DataFrame(poli_columns)\n",
    "    x_poli = pd.concat([x,poli_df], axis=1)\n",
    "    return x_poli\n",
    "\n",
    "\n",
    "  def fit_SGD(self, X, y, reg, lr, epochs):\n",
    "    for i in range(epochs):\n",
    "      indices = list(range(len(X)))\n",
    "      random.shuffle(indices)\n",
    "\n",
    "      for sample in indices:\n",
    "        #Calculo dos erros\n",
    "        y_pred=(X.iloc[sample]*self.w).sum()# esta certo\n",
    "        y_sig=1 / (1 + np.exp(-y_pred))# esta certo\n",
    "        error_np=y.iloc[sample]-y_sig# esta certo\n",
    "        error=error_np.item()#esta certo\n",
    "        \n",
    "        #ajuste dos Ws    \n",
    "        w_arr = np.array(self.w)#esta certo\n",
    "        inter = lr*error*X.iloc[sample]#esta certo\n",
    "        w_novo = w_arr + inter#esta certo\n",
    "        self.w=w_novo\n",
    "        \n",
    "        #Calculo da loss\n",
    "        self.loss_function(X.iloc[sample], y, reg)\n",
    "        \n",
    "      \n",
    "  def sigma(self,x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "      \n",
    "  def loss_function(self, x, y,reg):\n",
    "    w=np.array(self.w)\n",
    "    x_arr=x.to_numpy()\n",
    "    y_arr=y.to_numpy()\n",
    "\n",
    "    N = len(y_arr)#Numero de amostras\n",
    "    p = np.dot(x_arr, w)#Produto interno para cada xi\n",
    "    sigma = 1/(1+np.exp(-p))\n",
    "    epsilon = 1e-15# sujeira\n",
    "    sigma = np.clip(sigma, epsilon, 1 - epsilon)# Garante que não ocorra log(0)\n",
    "    loss = -(1/N)*np.sum(y_arr*np.log(sigma)+(1-y_arr)*np.log(1-sigma)) #Calcula a perda e salva na lista\n",
    "    self.losses.append(loss)\n",
    "    \n",
    "\n",
    "  def predict(self, X):\n",
    "    y=0\n",
    "    y_pred=[]# Lista para salvar as predições\n",
    "    df_bias = pd.DataFrame({'bias':[1]*len(X)})\n",
    "    x_poli = self.polinomial_transfomation(X,self.n)\n",
    "    X_bias=pd.concat([df_bias,x_poli], axis=1)\n",
    "    for sample in range(len(X_bias)):\n",
    "      y_sigma=self.sigma((X_bias.iloc[sample]*self.w).sum())# Calcula a predição \n",
    "      y_pred.append(0 if y_sigma<=0.5 else 1)# Aplica a função degrau para definir a classe e salva na lista\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimento dos modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=breast.iloc[:, 0:30]  \n",
    "y=breast[['y']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividindo os dados em treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "X_train = X_train.reset_index(drop=True)\n",
    "y_train = y_train.reset_index(drop=True)\n",
    "X_test = X_test.reset_index(drop=True)\n",
    "y_test = y_test.reset_index(drop=True)\n",
    "\n",
    "# Normalizando os dados\n",
    "norm=Nomalizer()\n",
    "norm.fit(X_train,y_train)\n",
    "norm_Trx,norm_Try=norm.normalize(X_train,y_train)\n",
    "norm_Tsx,norm_Tsy=norm.normalize(X_test,y_test)\n",
    "\n",
    "\n",
    "# Treinando um modelo\n",
    "model = LogisticClassifier()\n",
    "model.fit(norm_Trx,y_train,n=1, reg=1, lr=0.1, epochs=100)\n",
    "\n",
    "# Fazendo previsões\n",
    "y_pred = model.predict(norm_Tsx)\n",
    "\n",
    "# Contagem para de TP,FN,FP,TN para calcular metricas e matriz de confusão\n",
    "TP = 0  # Verdadeiro Positivo\n",
    "FN = 0  # Falso Negativo\n",
    "FP = 0  # Falso Positivo\n",
    "TN = 0  # Verdadeiro Negativo\n",
    "\n",
    "\n",
    "indices = list(range(len(y_pred)))\n",
    "for i in indices:\n",
    "    if y_test['y'][i] == 1 and y_pred[i] == 1:\n",
    "        TP += 1\n",
    "    elif y_test['y'][i] == 0 and y_pred[i] == 0:\n",
    "        TN += 1\n",
    "    elif y_test['y'][i] == 0 and y_pred[i] == 1:\n",
    "        FP += 1\n",
    "    elif y_test['y'][i] == 1 and y_pred[i] == 0:\n",
    "        FN += 1\n",
    "\n",
    "matriz_confusao = np.array([[TP, FN],\n",
    "                            [FP, TN]])\n",
    "print(\"/////////////////////////////////////////////////\")\n",
    "\n",
    "# Calculo da acuracia\n",
    "acuracia = (TP + TN) / len(norm_Tsy)\n",
    "print(\"acuracia do modelo: \",acuracia)\n",
    "\n",
    "\n",
    "# Calculo da revocação\n",
    "revocacao = TP / (TP + FN)\n",
    "print(\"revocação do modelo: \",revocacao)\n",
    "\n",
    "# Calculando a precisão\n",
    "precisao = TP / (TP + FP) \n",
    "print(\"precisao do modelo: \",precisao)\n",
    "\n",
    "# Calculando f1-score\n",
    "f1_score = 2 * (precisao * revocacao) / (precisao + revocacao)\n",
    "print(\"f1-score do modelo: \",f1_score)\n",
    "\n",
    "# Criar o gráfico\n",
    "plt.figure(figsize=(6, 5))\n",
    "ax = sns.heatmap(matriz_confusao, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False)\n",
    "\n",
    "# Configurações do gráfico\n",
    "ax.set_title(\"Matriz de Confusão\")\n",
    "ax.set_xlabel(\"Previsão\")\n",
    "ax.set_ylabel(\"Valor Real\")\n",
    "\n",
    "# Adicionando rótulos aos eixos\n",
    "ax.xaxis.set_ticklabels([\"Positivo\", \"Negativo\"])\n",
    "ax.yaxis.set_ticklabels([\"Positivo\", \"Negativo\"])\n",
    "\n",
    "# Exibir o gráfico\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurando o KFold\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Para armazenar métricas de cada fold\n",
    "mse_scores = []\n",
    "acuracias =[]\n",
    "revocacoes=[]\n",
    "precisoes=[]\n",
    "f1_scores=[]\n",
    "\n",
    "# Loop pelos folds\n",
    "for train_index, test_index in kf.split(x):\n",
    "    # Dividindo os dados em treino e teste\n",
    "    X_train, X_test = x.iloc[train_index], x.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    X_train = X_train.reset_index(drop=True)\n",
    "    y_train = y_train.reset_index(drop=True)\n",
    "    X_test = X_test.reset_index(drop=True)\n",
    "    y_test = y_test.reset_index(drop=True)\n",
    "\n",
    "    # Normalizando os dados\n",
    "    norm=Nomalizer()\n",
    "    norm.fit(X_train,y_train)\n",
    "    norm_Trx,norm_Try=norm.normalize(X_train,y_train)\n",
    "    norm_Tsx,norm_Tsy=norm.normalize(X_test,y_test)\n",
    "\n",
    "\n",
    "    # Treinando um modelo\n",
    "    model = LogisticClassifier()\n",
    "    model.fit(norm_Trx,norm_Try,n=1, reg=1, lr=0.001, epochs=50)\n",
    "\n",
    "    # Fazendo previsões\n",
    "    y_pred = model.predict(norm_Tsx)\n",
    "\n",
    "    # Contagem para de TP,FN,FP,TN para calcular metricas e matriz de confusão\n",
    "    TP = 0  # Verdadeiro Positivo\n",
    "    FN = 0  # Falso Negativo\n",
    "    FP = 0  # Falso Positivo\n",
    "    TN = 0  # Verdadeiro Negativo\n",
    "\n",
    "    indices = list(range(len(y_pred)))\n",
    "    for i in indices:\n",
    "        if y_test['y'][i] == 1 and y_pred[i] == 1:\n",
    "            TP += 1\n",
    "        elif y_test['y'][i] == 0 and y_pred[i] == 0:\n",
    "            TN += 1\n",
    "        elif y_test['y'][i] == 0 and y_pred[i] == 1:\n",
    "            FP += 1\n",
    "        elif y_test['y'][i] == 1 and y_pred[i] == 0:\n",
    "            FN += 1\n",
    "\n",
    "    matriz_confusao = np.array([[TP, FN],\n",
    "                                [FP, TN]])\n",
    "    print(\"/////////////////////////////////////////////////\")\n",
    "\n",
    "    # Calculo da acuracia\n",
    "    acuracia = (TP + TN) / len(norm_Tsy)\n",
    "    print(\"acuracia do modelo: \",acuracia)\n",
    "    acuracias.append(acuracia)\n",
    "\n",
    "    # Calculo da revocação\n",
    "    revocacao = TP / (TP + FN)\n",
    "    revocacoes.append(revocacao)\n",
    "    print(\"revocação do modelo: \",revocacao)\n",
    "\n",
    "    # Calculando a precisão\n",
    "    precisao = TP / (TP + FP) \n",
    "    precisoes.append(precisao)\n",
    "    print(\"precisao do modelo: \",precisao)\n",
    "\n",
    "    # Calculando f1-score\n",
    "    f1_score = 2 * (precisao * revocacao) / (precisao + revocacao)\n",
    "    f1_scores.append(f1_score)\n",
    "    print(\"f1-score do modelo: \",f1_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exibindo o resultado\n",
    "print(\"/////////////////////////////////////////////////\")\n",
    "print(\"Metricas Acuracia:\")\n",
    "print(\"Acuracia médio:\", np.mean(acuracias))\n",
    "print(\"Desvio padrão Acuracia:\", np.std(acuracias))\n",
    "#print(\"Acuracia em cada fold:\", acuracias)\n",
    "print(\" \")\n",
    "\n",
    "print(\"Metricas Revocação:\")\n",
    "print(\"Revocação médio:\", np.mean(revocacoes))\n",
    "print(\"Desvio padrão Revocação:\", np.std(revocacoes))\n",
    "#print(\"Revocações em cada fold:\", revocacoes)\n",
    "print(\" \")\n",
    "\n",
    "print(\"Metricas Precisão:\")\n",
    "print(\"Precisão médio:\", np.mean(precisoes))\n",
    "print(\"Desvio padrão Precisão:\", np.std(precisoes))\n",
    "#print(\"Precisões em cada fold:\", precisoes)\n",
    "print(\" \")\n",
    "\n",
    "print(\"Metricas F1-score:\")\n",
    "print(\"F1-score médio:\", np.mean(f1_scores))\n",
    "print(\"Desvio padrão F1-score:\", np.std(f1_scores))\n",
    "#print(\"F1-scores em cada fold:\", f1_scores)\n",
    "print(\"/////////////////////////////////////////////////\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
